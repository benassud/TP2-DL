{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlsSt8kAh6/iuxyvD0jeax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benassud/TP2-DL/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Utils**"
      ],
      "metadata": {
        "id": "1XY0TJEqtjNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Drive { display-mode: \"form\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fizq8UtQ7X-i",
        "outputId": "4cb3785d-a22e-44a0-e687-5c55ea37b24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Git-Clone { display-mode: \"form\" }\n",
        "key = \\\n",
        "'''-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAlwAAAAdzc2gtcn\n",
        "NhAAAAAwEAAQAAAIEA+Ofo5gqfcXTg/rFmGiN6EgzQIJVi/51Oq+5/i8jKWpXSj2oZG7Gs\n",
        "MuoWSM9WTkYIujq2LDUpAOrOh9Lnqt4cKIsc8yc5aLhoZh1KB9HQUrmeDmCc3qH5AUwswS\n",
        "xsVNMxUhw3cFOzBBxDRPwSmtkuRngQngoi/p5B1VVD1EsVgTsAAAIIJFEMqSRRDKkAAAAH\n",
        "c3NoLXJzYQAAAIEA+Ofo5gqfcXTg/rFmGiN6EgzQIJVi/51Oq+5/i8jKWpXSj2oZG7GsMu\n",
        "oWSM9WTkYIujq2LDUpAOrOh9Lnqt4cKIsc8yc5aLhoZh1KB9HQUrmeDmCc3qH5AUwswSxs\n",
        "VNMxUhw3cFOzBBxDRPwSmtkuRngQngoi/p5B1VVD1EsVgTsAAAADAQABAAAAgGae1rrhbl\n",
        "NMqObZJQtpzQ5cEgMdFC/nH2RrdFKheixW0PUn/SoZ2rEzKfTi5uZmoXqGck1PrZQfOv9s\n",
        "yO79nAWbCyNHEsG09NIacAO1lVp8eysDU/tDKGnzkAxLX3HNWEchwG4BvuVb1GLzAemqYI\n",
        "eRdIf9F/+aJuSbRxRyDO6hAAAAQBvoWpDxB3RdWSQDN4vNSmVs5FTvpRzch1xL5RC5YSeZ\n",
        "mzi5sIh4ngal71vpYw1SE3y6iK8QBPChqULKIqn8QBgAAABBAP+g2ORplH6VPd5vwHQuz4\n",
        "e5BKi18vYwdMjNNcJd4MvLxW5dTg06eHN6gG2qJNP9hMbqWBDSmGjFNQ5pMzaHm6UAAABB\n",
        "APlEj2uSFgTu8fuaDzlQj9+Qmzj0KQkqsZ2KrHd5ipvI83oMxIiErmx45ARp7sKVR/uxkn\n",
        "lor2g/Dcfv5H1nk18AAAATYmVuYXNzdWRAZ2l0aHViLmNvbQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "'''\n",
        "\n",
        "!mkdir -p /root/.ssh\n",
        "!ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "with open(r'/root/.ssh/id_rsa', 'w', encoding='utf8') as fh:\n",
        "    fh.write(key)\n",
        "!chmod 600 /root/.ssh/id_rsa\n",
        "\n",
        "!ssh -T git@github.com\n",
        "!git clone git@github.com:benassud/TP2-DL.git /content/TP2-DL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYUJzY2Qh5wU",
        "outputId": "353106f3-3ac4-4431-b977-7771ead77257"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-fc59fe75\n",
            "# github.com:22 SSH-2.0-babeld-fc59fe75\n",
            "# github.com:22 SSH-2.0-babeld-fc59fe75\n",
            "# github.com:22 SSH-2.0-babeld-fc59fe75\n",
            "# github.com:22 SSH-2.0-babeld-fc59fe75\n",
            "Warning: Permanently added the ECDSA host key for IP address '20.205.243.166' to the list of known hosts.\n",
            "Hi benassud/TP2-DL! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "Cloning into '/content/TP2-DL'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 36 (delta 12), reused 20 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (36/36), 86.63 KiB | 195.00 KiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Git-Push {display-mode: \"form\"}\n",
        "!git config --global user.name \"benassud\"\n",
        "!git config --global user.email \"benas.sudzius@googlemail.com\"\n",
        "!git add -all\n",
        "!git commit -a -m \"remove test.py\"\n",
        "!git push origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENZJkMYksGM3",
        "outputId": "fc30fd14-cdac-44b4-c37a-b4010ff989bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: did you mean `--all` (with two dashes)?\n",
            "[main 00a6b03] remove test.py\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " delete mode 100644 test.py\n",
            "Enumerating objects: 3, done.\n",
            "Counting objects: 100% (3/3), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (2/2), done.\n",
            "Writing objects: 100% (2/2), 227 bytes | 227.00 KiB/s, done.\n",
            "Total 2 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To github.com:benassud/TP2-DL.git\n",
            "   90fa399..00a6b03  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model**"
      ],
      "metadata": {
        "id": "R5bYoLwi61yU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Init"
      ],
      "metadata": {
        "id": "Y4FjwqRp9T8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!sudo apt-get update\n",
        "#!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "#!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents[reverb]\n",
        "!pip install pyglet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TNf1T-Y6sM0",
        "outputId": "00e7da8a-d01d-480e-d13e-1eb520d69bf8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.16.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents[reverb])\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (8.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Collecting pygame==2.1.3 (from tf-agents[reverb])\n",
            "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-probability~=0.19.0 (from tf-agents[reverb])\n",
            "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rlds (from tf-agents[reverb])\n",
            "  Downloading rlds-0.1.8-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-reverb~=0.11.0 (from tf-agents[reverb])\n",
            "  Downloading dm_reverb-0.11.0-cp310-cp310-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.32.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.19.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-agents[reverb]) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.2.2)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697645 sha256=04fbb8e95d92de3dac1d8c18ce791a7bc66b367e2252118b4e369772775a70a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
            "Successfully built gym\n",
            "Installing collected packages: tensorflow-probability, rlds, pygame, gym, dm-reverb, tf-agents\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.20.1\n",
            "    Uninstalling tensorflow-probability-0.20.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.20.1\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.3.0\n",
            "    Uninstalling pygame-2.3.0:\n",
            "      Successfully uninstalled pygame-2.3.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed dm-reverb-0.11.0 gym-0.23.0 pygame-2.1.3 rlds-0.1.8 tensorflow-probability-0.19.0 tf-agents-0.16.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyglet\n",
            "  Downloading pyglet-2.0.7-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.0/841.0 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-2.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "import reverb\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import ActionOffsetWrapper\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.environments import py_environment\n",
        "\n"
      ],
      "metadata": {
        "id": "r6oI8nFn-ueQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "c7108884-b916-465c-ebe6-cec67dc18782"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Game Params\n",
        "BOARD_SIZE = 32 \n",
        "\n",
        "class SnakePyEnvironment(py_environment.PyEnvironment):\n",
        "  \"\"\"PlaneStrike environment for TF Agents.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               width=BOARD_SIZE,\n",
        "               height=BOARD_SIZE,\n",
        "               food_amount=1,\n",
        "               border=0,\n",
        "               grass_growth=0,\n",
        "               max_grass=0,\n",
        "               discount=0.9,\n",
        "               max_steps=1000):\n",
        "    super(SnakePyEnvironment, self).__init__()\n",
        "    self._width = width\n",
        "    self._height = height\n",
        "    self._board = np.zeros((height,width,3),dtype = np.float32)\n",
        "    self._food_amount = food_amount\n",
        "    self._border = border\n",
        "    self._grass_growth = grass_growth\n",
        "    self._grass = np.zeros( (height,width) ) + max_grass\n",
        "    self._max_grass = max_grass\n",
        "    self._discount = discount\n",
        "    self._max_steps = max_steps\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        (), np.int32, minimum=-1, maximum=1)  \n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        (self._height, self._width, 3),\n",
        "        np.float32,\n",
        "        minimum=0,\n",
        "        maximum=1)\n",
        "    self._time_step_spec = ts.time_step_spec(self._observation_spec)\n",
        "    self._reset()\n",
        "\n",
        "  def _create_apples(self):\n",
        "    \"create a new apple away from the snake\"\n",
        "    while len(self._apples)<self._food_amount:\n",
        "        apple = (np.random.randint(0,self._height-1), np.random.randint(0,self._width-1) )\n",
        "        while apple in self._snake:\n",
        "            apple = (np.random.randint(0,self._height-1), np.random.randint(0,self._width-1) )\n",
        "        self._apples.append(apple)\n",
        "\n",
        "  def _create_snake(self):\n",
        "    \"create a snake, size 3, at random position and orientation\"\n",
        "    x = np.random.randint(5, self._width-5 )   # not t0o close to border\n",
        "    y = np.random.randint(5, self._height-5 )\n",
        "    self._direction = np.random.randint(0,4)\n",
        "    self._snake = []\n",
        "    for i in range(5):\n",
        "        if self._direction==0:\n",
        "            y = y+1\n",
        "        elif self._direction==1:\n",
        "            x = x-1\n",
        "        elif self._direction==2:\n",
        "            y = y-1\n",
        "        elif self._direction==3:\n",
        "            x = x+1\n",
        "        self._snake.append( (y,x) )\n",
        "\n",
        "  def _grow_snake(self, d):\n",
        "    \"add one position to snake head (0=up, 1=right, 2=down, 3=left)\"\n",
        "    y,x = self._snake[0]\n",
        "    if d == 0:\n",
        "        y = y-1\n",
        "    elif d == 1:\n",
        "        x = x+1\n",
        "    elif d == 2:\n",
        "        y = y+1\n",
        "    else:\n",
        "        x = x-1\n",
        "    self._snake.insert(0,(y,x))\n",
        "\n",
        "  def _check_collisions(self):\n",
        "    \"check if game is over by colliding with edge or itself\"\n",
        "    # just need to check snake's head\n",
        "    x,y = self._snake[0]\n",
        "    if (x == -1 or x == self._height \n",
        "        or y == -1 or y == self._width\n",
        "        or (x,y) in self._snake[1:]):\n",
        "        self._done = True\n",
        "\n",
        "  def current_time_step(self):\n",
        "    return self._current_time_step\n",
        "\n",
        "  def observation_spec(self):\n",
        "    \"\"\"Return observation_spec.\"\"\"\n",
        "    return self._observation_spec\n",
        "\n",
        "  def action_spec(self):\n",
        "    \"\"\"Return action_spec.\"\"\"\n",
        "    return self._action_spec\n",
        "\n",
        "  def _reset(self):\n",
        "    \"\"\"Return initial_time_step.\"\"\"\n",
        "    self._score = 0\n",
        "    self._done = False\n",
        "    self._create_snake()\n",
        "    self._apples = []\n",
        "    self._create_apples()\n",
        "    self._grass[:,:] =  self._max_grass\n",
        "    self._board = self._board_state()\n",
        "    return ts.restart(self._board)\n",
        "\n",
        "  def _step(self, action):\n",
        "    \"\"\"Apply action and return new time_step.\"\"\"\n",
        "    #Add when episode shoud be ended\n",
        "    \n",
        "    direction = int(action)\n",
        "    assert -1<=direction<=1        \n",
        "    self._direction+=direction\n",
        "    if self._direction<0:\n",
        "        self._direction = 3\n",
        "    elif self._direction>3:\n",
        "        self._direction = 0\n",
        "    self._grow_snake(self._direction)  # two steps: grow+remove last\n",
        "    if self._snake[0] in self._apples:            \n",
        "        self._apples.remove(self._snake[0])\n",
        "        reward = 1\n",
        "        self._create_apples()     # new apple\n",
        "    else:\n",
        "        self._snake.pop()\n",
        "        self._check_collisions()\n",
        "        if self._done:\n",
        "            reward = -1\n",
        "            return ts.termination(self._board, reward)\n",
        "        else:\n",
        "            reward = 0\n",
        "    if reward>=0:\n",
        "        x,y = self._snake[0]\n",
        "        reward += self._grass[x,y]\n",
        "        self._grass[x,y] = 0\n",
        "        self._score+=reward\n",
        "        self._grass += self._grass_growth \n",
        "        self._grass[self._grass>self._max_grass] = self._max_grass\n",
        "        self._board = self._board_state()\n",
        "    return ts.transition(self._board, reward, self._discount)\n",
        "\n",
        "  def _board_state(self, mode='human', close=False):\n",
        "    \"Render the environment\"\n",
        "    self._board[:,:,:] = 0\n",
        "    if self._max_grass>0:\n",
        "        self._board[:,:,1] = self._grass/self._max_grass * 0.3\n",
        "    if not self._done:\n",
        "        x,y = self._snake[0]\n",
        "        self._board[x,y,:] = 1\n",
        "    for x,y in self._snake[1:]:\n",
        "        self._board[x,y,0] = 1\n",
        "    for x,y in self._apples: \n",
        "        self._board[x,y,1] = 1\n",
        "    if self._border == 0:\n",
        "        return self._board\n",
        "    else:\n",
        "        h,w,_ = self.board.shape\n",
        "        board = np.full((h+self._border*2,w+self._border*2,3),0.5,np.float32)\n",
        "        board[self._border:-self._border,self._border:-self._border] = self._board \n",
        "        return board\n",
        "      \n",
        "  def render(self):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(self._board)\n",
        "    plt.axis('off')\n",
        "    plt.close()\n",
        "    plt.savefig('42')  \n",
        "    print(np.max(self._board))\n",
        "    arr = np.array(self._board *255, dtype=np.uint8)\n",
        "    print(np.max(arr))\n",
        "    return arr \n",
        "\n",
        "train_py_env = SnakePyEnvironment()\n",
        "eval_py_env = SnakePyEnvironment()\n",
        "env = SnakePyEnvironment()\n",
        "\n",
        "train_py_env_offset = ActionOffsetWrapper(train_py_env)\n",
        "eval_py_env_offset = ActionOffsetWrapper(eval_py_env)\n",
        "env = ActionOffsetWrapper(env)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env_offset)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(train_py_env_offset)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4FaoeBOFu_w4"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 20 #20000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 10 # 100  # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 1000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 2 #10  # @param {type:\"integer\"}\n",
        "eval_interval = 10 #1000  # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "4QhBD9f-LY48"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_layer_params = (100, 50)\n",
        "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "# Define a helper function to create Dense layers configured with the right\n",
        "# activation and kernel initializer.\n",
        "def dense_layer(num_units):\n",
        "  return tf.keras.layers.Dense(\n",
        "      num_units,\n",
        "      activation=tf.keras.activations.relu,\n",
        "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
        "\n",
        "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
        "# with `num_actions` units to generate one q_value per available action as\n",
        "# its output.\n",
        "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = sequential.Sequential([tf.keras.layers.Flatten(input_shape=\\\n",
        "          (BOARD_SIZE, BOARD_SIZE, 3))] + dense_layers + [q_values_layer])"
      ],
      "metadata": {
        "id": "6RF5Id7VUP7h"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ],
      "metadata": {
        "id": "d536y5yFUw8f"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy"
      ],
      "metadata": {
        "id": "GT2snXAtVEYe"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())"
      ],
      "metadata": {
        "id": "MteKRopBVHSE"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]\n"
      ],
      "metadata": {
        "id": "KVMWssxBVSmv"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(\n",
        "      agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "    replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_max_length,\n",
        "    sampler=reverb.selectors.Uniform(),\n",
        "    remover=reverb.selectors.Fifo(),\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "    signature=replay_buffer_signature)\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name=table_name,\n",
        "    sequence_length=2,\n",
        "    local_server=reverb_server)\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "  replay_buffer.py_client,\n",
        "  table_name,\n",
        "  sequence_length=2)"
      ],
      "metadata": {
        "id": "5twXsYE4tkjT"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py_driver.PyDriver(\n",
        "    env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      random_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps, max_episodes=10).run(train_py_env.reset())\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step.\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "# Reset the environment.\n",
        "time_step = train_py_env.reset()\n",
        "\n",
        "# Create a driver to collect experience.\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      agent.collect_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration, max_episodes=7)\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps and save to the replay buffer.\n",
        "  time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO0-Bu4lwtIT",
        "outputId": "94ad1915-37ba-4000-d5b9-8be37a295fd3"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 10: Average Return = -1.0\n",
            "step = 20: Average Return = -1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_step = eval_env.reset()\n",
        "print(np.max(time_step.observation))\n",
        "action_step = agent.policy.action(time_step)\n",
        "time_step2 = eval_env.step(action_step.action)\n",
        "\n",
        "np.max(time_step.observation - time_step2.observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l19M814HgE0",
        "outputId": "50c55cf6-7d59-4356-a0b0-01921f093c77"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
        "  filename = filename + \".mp4\"\n",
        "  with imageio.get_writer(filename, fps=fps) as video:\n",
        "    for _ in range(num_episodes):\n",
        "      time_step = eval_env.reset()\n",
        "      video.append_data(eval_py_env.render())\n",
        "      while not time_step.is_last():\n",
        "        action_step = policy.action(time_step)\n",
        "        time_step = eval_env.step(action_step.action)\n",
        "        video.append_data(eval_py_env.render())\n",
        "  return embed_mp4(filename)\n",
        "\n",
        "create_policy_eval_video(agent.policy, \"trained-agent2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ThTL3P0GzQ2e",
        "outputId": "22b34fff-e52b-4a76-e4ea-b947b93c2053"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n",
            "1.0\n",
            "255\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJVLp57V73s_"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}